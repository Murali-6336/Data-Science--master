{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apR8ejZ7G1ca"
   },
   "source": [
    "# Document Classification & Clustering - Lecture\n",
    "\n",
    "What could we do with the document-term-matrices (dtm[s]) created in the previous notebook? We could visualize them or train an algorithm to do some specific task. We have covered both classification and clustering before, so we won't focus on the particulars of algorithms. Instead we'll focus on the unique problems of dealing with text input for these models.\n",
    "\n",
    "## Contents\n",
    "* [Part 1](#p1): Vectorize a whole Corpus\n",
    "* [Part 2](#p2): Tune the vectorizer\n",
    "* [Part 3](#p3): Apply Vectorizer to Classification problem\n",
    "* [Part 4](#p4): Introduce topic modeling on text data\n",
    "\n",
    "**Business Case**: Your managers at Smartphone Inc. have asked to develop a system to bucket text messages into two categories: **spam** and **not spam (ham)**. The system will be implemented on your companies products to help users identify suspicious texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PtOOBxaifpY"
   },
   "source": [
    "# Spam Filter - Count Vectorization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuvyMXrajKwR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtQczusKkV6b"
   },
   "source": [
    "**Import the data and take a look at it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tqjh7vXrjRIm",
    "outputId": "f3976c88-9add-4880-f559-4790bd81cfe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "5567  spam   \n",
       "5568   ham   \n",
       "5569   ham   \n",
       "5570   ham   \n",
       "5571   ham   \n",
       "\n",
       "                                                                                                                                                                  text  \\\n",
       "5567  This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.   \n",
       "5568                                                                                                                              Will ü b going to esplanade fr home?   \n",
       "5569                                                                                                         Pity, * was in mood for that. So...any other suggestions?   \n",
       "5570                                     The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl. Its true to its name   \n",
       "\n",
       "      label_num  \n",
       "5567          1  \n",
       "5568          0  \n",
       "5569          0  \n",
       "5570          0  \n",
       "5571          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load():\n",
    "    url = \"https://raw.githubusercontent.com/sokjc/BayesNotBaes/master/sms.tsv\"\n",
    "\n",
    "    df = pd.read_csv(url, sep='\\t', header=None, \n",
    "                     names=['label', 'msg'])\n",
    "    df = df.rename(columns={\"msg\":\"text\"})\n",
    "    \n",
    "    # encode target\n",
    "    df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "    \n",
    "    return df\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "df = load()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yczMV4ock3T9"
   },
   "source": [
    "Notice that this text isn't as coherent as the job listings. We'll proceed like normal though. \n",
    "\n",
    "What is the ratio of Spam to Ham messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "90ajEqS0jsNH",
    "outputId": "823615d7-db7f-4ee1-90cc-5102adc0567f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wE9G1fxwKcRx",
    "outputId": "632959fb-fa14-4961-a94c-2de32100d078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FryOCtIm1ts"
   },
   "source": [
    "**Model Validation - Train Test Split** (Cross Validation would be better here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzjs9vdyniq7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text']\n",
    "y = df['label_num']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "a42hg4S4vaLv",
    "outputId": "d6954710-2151-4130-a1bc-bfe32fcb0d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,)\n",
      "(1115,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape,\n",
    "      y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnv4EIJLmTuM"
   },
   "source": [
    "**Count Vectorizer**\n",
    "\n",
    "Today we're just going to let Scikit-Learn do our text cleaning and preprocessing for us.\n",
    "\n",
    "Lets run our vectorizer on our text messages and take a peek at the tokenization of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "I1Vzh1EGrqeR",
    "outputId": "367cf9f0-6656-4301-ba01-7ef9d79acdea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['150p16', '150pm', '150ppermesssubscription', '150ppm', '150ppmpobox10183bhamb64xe', '150ppmsg', '150pw', '151', '153', '15541', '16', '165', '1680', '169', '177', '18', '1843', '18p', '18yrs', '195', '1apple', '1b6a5ecef91ff9', '1cup', '1da', '1er']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=None, ngram_range=(1,1), \n",
    "                             stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "print(vectorizer.get_feature_names()[300:325])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lu0yhnpssWur"
   },
   "source": [
    "Now we'll complete the vectorization with `.transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "t0dz2qUKldSU",
    "outputId": "b8c4a110-5019-4d76-ceca-7c8ed6b06b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 7443)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000pes  008704050406  0089  0121  01223585334  0125698789  02  \\\n",
       "0   0    0       0             0     0     0            0           0   0   \n",
       "1   0    0       0             0     0     0            0           0   0   \n",
       "2   0    0       0             0     0     0            0           0   0   \n",
       "3   0    0       0             0     0     0            0           0   0   \n",
       "4   0    0       0             0     0     0            0           0   0   \n",
       "\n",
       "   0207  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada  èn  ú1  〨ud  \n",
       "0     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "1     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "2     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "3     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "4     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "\n",
       "[5 rows x 7443 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "# not necessary to save to a dataframe, but helpful for previewing\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), \n",
    "                                  columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CKL75Uqtu8J"
   },
   "source": [
    "We also need to vectorize our `X_test` data, but **we need to use the same vocabulary as the training dataset**, so we'll just call `.transform()` on `X_test` to get our `X_test_vectorized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "iJ2gw3GLt6jE",
    "outputId": "38f663af-8157-405f-8a92-db87037290a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 7443)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000pes  008704050406  0089  0121  01223585334  0125698789  02  \\\n",
       "0   0    0       0             0     0     0            0           0   0   \n",
       "1   0    0       0             0     0     0            0           0   0   \n",
       "2   0    0       0             0     0     0            0           0   0   \n",
       "3   0    0       0             0     0     0            0           0   0   \n",
       "4   0    0       0             0     0     0            0           0   0   \n",
       "\n",
       "   0207  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada  èn  ú1  〨ud  \n",
       "0     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "1     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "2     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "3     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "4     0  ...      0       0    0          0     0     0      0   0   0    0  \n",
       "\n",
       "[5 rows x 7443 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), \n",
    "                                 columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAWEHttfszBQ"
   },
   "source": [
    "Lets run some classification models and see what kind of accuracy we can get!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-f3Sz4Twl3P"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def assess_model(model, X_train, X_test, \n",
    "                 y_train, y_test, vect_type='Count'):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    result = {}\n",
    "    result['model'] = str(model).split('(')[0]\n",
    "    result['acc_train'] = accuracy_score(y_train, train_predictions)\n",
    "    result['acc_test'] = accuracy_score(y_test, test_predictions)\n",
    "    result['vect_type'] = vect_type\n",
    "    print(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "qWRLCgevs8tP",
    "outputId": "1022524b-0c69-4183-b522-48f9244a0c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'acc_train': 0.9957370428539376, 'acc_test': 0.9766816143497757, 'vect_type': 'Count'}\n",
      "{'model': 'MultinomialNB', 'acc_train': 0.9934933811981154, 'acc_test': 0.9856502242152466, 'vect_type': 'Count'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\City_Year\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'RandomForestClassifier', 'acc_train': 0.9977563383441777, 'acc_test': 0.9721973094170404, 'vect_type': 'Count'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.995737</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985650</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                   model vect_type\n",
       "0  0.976682   0.995737      LogisticRegression     Count\n",
       "1  0.985650   0.993493           MultinomialNB     Count\n",
       "2  0.972197   0.997756  RandomForestClassifier     Count"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinomial Naive Bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [LogisticRegression(random_state=42, solver='lbfgs'),\n",
    "          MultinomialNB(),\n",
    "          RandomForestClassifier()]\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    result = assess_model(\n",
    "        model,\n",
    "        X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hc-FmCIzyyGt"
   },
   "source": [
    "# Spam Filter - TF-IDF Vectorization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "IPGVmNN3y-sX",
    "outputId": "c3ff2bca-93e2-443b-b46d-864258296c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=None, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "# fit to train\n",
    "vectorizer.fit(X_train)\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "kdJnMS86zyTf",
    "outputId": "c3a7c463-8d15-446e-e01b-9ff4c422768d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 7443)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000pes  008704050406  0089  0121  01223585334  0125698789   02  \\\n",
       "0  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "1  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "2  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "3  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "4  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "\n",
       "   0207  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada   èn   ú1  〨ud  \n",
       "0   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "1   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "2   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "3   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "4   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 7443 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to train\n",
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(),\n",
    "                                  columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "yZY7QkM50EiN",
    "outputId": "6fe1f40c-9247-4cd4-de73-1080891c944d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 7443)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000pes  008704050406  0089  0121  01223585334  0125698789   02  \\\n",
       "0  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "1  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "2  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "3  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "4  0.0  0.0     0.0           0.0   0.0   0.0          0.0         0.0  0.0   \n",
       "\n",
       "   0207  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada   èn   ú1  〨ud  \n",
       "0   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "1   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "2   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "3   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "4   0.0  ...    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 7443 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to test\n",
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(),\n",
    "                                 columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "_bhI1BPe0N0q",
    "outputId": "dc834747-deb1-4fb1-ed24-783e0a114575",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'acc_train': 0.9703836661431456, 'acc_test': 0.9551569506726457, 'vect_type': 'Tfidf'}\n",
      "{'model': 'MultinomialNB', 'acc_train': 0.982499439084586, 'acc_test': 0.9659192825112107, 'vect_type': 'Tfidf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\City_Year\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'RandomForestClassifier', 'acc_train': 0.9966345075162666, 'acc_test': 0.9695067264573991, 'vect_type': 'Tfidf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.995737</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985650</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.970384</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965919</td>\n",
       "      <td>0.982499</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969507</td>\n",
       "      <td>0.996635</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                   model vect_type\n",
       "0  0.976682   0.995737      LogisticRegression     Count\n",
       "1  0.985650   0.993493           MultinomialNB     Count\n",
       "2  0.972197   0.997756  RandomForestClassifier     Count\n",
       "3  0.955157   0.970384      LogisticRegression     Tfidf\n",
       "4  0.965919   0.982499           MultinomialNB     Tfidf\n",
       "5  0.969507   0.996635  RandomForestClassifier     Tfidf"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [LogisticRegression(random_state=42, solver='lbfgs'),\n",
    "          MultinomialNB(),\n",
    "          RandomForestClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    result = assess_model(\n",
    "        model,\n",
    "        X_train_vectorized, X_test_vectorized, y_train, y_test,\n",
    "        vect_type='Tfidf')\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cm4RkbL01uBh"
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "The objective of **sentiment analysis** is to take a text phrase and determine if its sentiment is: Postive, Neutral, or Negative. \n",
    "\n",
    "Suppose that you wanted to use NLP to classify reviews for your company's products as either positive, neutral, or negative. Maybe you don't trust the star ratings left by the users and you want an additional measure of sentiment from each review - maybe you would use this as a feature generation technique for additional modeling, or to identify disgruntled customers and reach out to them to improve your customer service, etc. Sentiment Analysis has also been used heavily in stock market price estimation by trying to track the sentiment of the tweets of individuals after breaking news comes out about a company.\n",
    "\n",
    "Does every word in each review contribute to its overall sentiment? Not really. Stop words for example don't really tell us much about the overall sentiment of the text, so just like we did before, we will discard them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okxG3HwRWEuc"
   },
   "source": [
    "### NLTK Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "skc_zUROF7mL",
    "outputId": "afa3ca0d-04fa-429f-cbc1-8fdb7949226c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movie_reviews():\n",
    "    from nltk.corpus import movie_reviews\n",
    "    nltk.download('movie_reviews')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    print(\"Total reviews:\", len(movie_reviews.fileids()))\n",
    "    print(\"Positive reviews:\", len(movie_reviews.fileids('pos')))\n",
    "    print(\"Negative reviews:\", len(movie_reviews.fileids('neg')))\n",
    "    \n",
    "    # Get Reviews and randomize\n",
    "    reviews = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "    random.shuffle(reviews)\n",
    "    \n",
    "    documents = []\n",
    "    sentiments = []\n",
    "\n",
    "    for review in reviews:\n",
    "        # Add sentiment to list\n",
    "        if review[1] == \"pos\":\n",
    "            sentiments.append(1)\n",
    "        else:\n",
    "            sentiments.append(0)\n",
    "\n",
    "        # Add text to list\n",
    "        review_text = \" \".join(review[0])\n",
    "        documents.append(review_text)\n",
    "\n",
    "    df = pd.DataFrame({\"text\": documents, \n",
    "                       \"sentiment\": sentiments})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "gRO9_tfvIcEM",
    "outputId": "83fb0a8b-557a-4ec2-92a8-e1afb435696f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Total reviews: 2000\n",
      "Positive reviews: 1000\n",
      "Negative reviews: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aspiring broadway composer robert ( aaron williams ) secretly carries a torch for his best friend , struggling actor marc ( michael shawn lucas ) . the problem is , marc only has eyes for \" perfec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it happens every year -- the days get longer , the weather gets warmer and the studios start releasing their big - budget blockbusters . this year ' s crop already seems inferior to that of past s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>` the skulls ' is a laughably bad thriller , a teen - orientated doppelganger of ` the firm ' so blazingly ridiculous that it caused me to drift into a hypnotic stupor . certain moments are so pre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the exception of their surrealistic satire barton fink , the films of joel and ethan coen fit into two broad categories : quirky and sometimes darkly humorous takes on the \" film noir \" genre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disney cements their place in the forefront of feature animation with the release of their latest animated adventure , mulan . while it adheres a bit too close to the disney formula to be perfect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  aspiring broadway composer robert ( aaron williams ) secretly carries a torch for his best friend , struggling actor marc ( michael shawn lucas ) . the problem is , marc only has eyes for \" perfec...   \n",
       "1  it happens every year -- the days get longer , the weather gets warmer and the studios start releasing their big - budget blockbusters . this year ' s crop already seems inferior to that of past s...   \n",
       "2  ` the skulls ' is a laughably bad thriller , a teen - orientated doppelganger of ` the firm ' so blazingly ridiculous that it caused me to drift into a hypnotic stupor . certain moments are so pre...   \n",
       "3  with the exception of their surrealistic satire barton fink , the films of joel and ethan coen fit into two broad categories : quirky and sometimes darkly humorous takes on the \" film noir \" genre...   \n",
       "4  disney cements their place in the forefront of feature animation with the release of their latest animated adventure , mulan . while it adheres a bit too close to the disney formula to be perfect ...   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_movie_reviews()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyrzWJo6VVpk"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRpgpiZ4VVAM"
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlH7u0pPaV86"
   },
   "source": [
    "# Sentiment Analysis - CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hh_JY67SWXNS"
   },
   "source": [
    "## Generate vocabulary from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "d9hiHBouSvBC",
    "outputId": "d5afde59-cf1a-4f22-830e-712aadd1651a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=None, ngram_range=(1,1), \n",
    "                             stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "1Ofvut25XgDU",
    "outputId": "d92946f3-57b2-4a3b-e6b3-cce51e43e6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 35989)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>05425</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zuehlke</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  03  04  05  05425  10  100  1000  ...  zuehlke  zuko  \\\n",
       "0   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "1   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "2   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "3   0    0    0   0   0   0      0   1    0     0  ...        0     0   \n",
       "4   0    0    0   0   0   0      0   1    1     0  ...        0     0   \n",
       "\n",
       "   zukovsky  zulu  zurg  zus  zweibel  zwick  zwigoff  zycie  \n",
       "0         0     0     0    0        0      0        1      0  \n",
       "1         0     0     0    0        0      0        0      0  \n",
       "2         0     0     0    0        0      0        0      0  \n",
       "3         0     0     0    0        0      0        0      0  \n",
       "4         0     0     0    0        0      0        0      0  \n",
       "\n",
       "[5 rows x 35989 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), \n",
    "                                  columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "Ni_sEpWzXp7j",
    "outputId": "741866b7-699b-41de-dc94-6d315fff0925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 35989)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>05425</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zuehlke</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  03  04  05  05425  10  100  1000  ...  zuehlke  zuko  \\\n",
       "0   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "1   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "2   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "3   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "4   0    0    0   0   0   0      0   0    0     0  ...        0     0   \n",
       "\n",
       "   zukovsky  zulu  zurg  zus  zweibel  zwick  zwigoff  zycie  \n",
       "0         0     0     0    0        0      0        0      0  \n",
       "1         0     0     0    0        0      0        0      0  \n",
       "2         0     0     0    0        0      0        0      0  \n",
       "3         0     0     0    0        0      0        0      0  \n",
       "4         0     0     0    0        0      0        0      0  \n",
       "\n",
       "[5 rows x 35989 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2e7FAmlMX2e-"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=42, solver='lbfgs'),\n",
    "          MultinomialNB(),\n",
    "          RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'acc_train': 1.0, 'acc_test': 0.8375, 'vect_type': 'Count'}\n",
      "{'model': 'MultinomialNB', 'acc_train': 0.975625, 'acc_test': 0.785, 'vect_type': 'Count'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\City_Year\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'RandomForestClassifier', 'acc_train': 0.99, 'acc_test': 0.725, 'vect_type': 'Count'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.975625</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                   model vect_type\n",
       "0    0.8375   1.000000      LogisticRegression     Count\n",
       "1    0.7850   0.975625           MultinomialNB     Count\n",
       "2    0.7250   0.990000  RandomForestClassifier     Count"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in models:\n",
    "    result = assess_model(\n",
    "        model,\n",
    "        X_train_vectorized, X_test_vectorized, y_train, y_test,\n",
    "        vect_type='Count')\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18n4qfR7a6Sk"
   },
   "source": [
    "# Sentiment Analysis - tfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "FojVcXZTbJQG",
    "outputId": "c4e1d3c5-0081-4a04-b907-26b2e48932c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=2000, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1,2),\n",
    "                             min_df = 5, max_df = .80,\n",
    "                             stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "Yp6MxwlKbZ3s",
    "outputId": "93527670-06fc-44a5-e2b9-99687fe22d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>years later</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>young man</th>\n",
       "      <th>younger</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078474</td>\n",
       "      <td>0.077244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.038514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039311</td>\n",
       "      <td>0.07021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000        10       100   12   13        15        17  1995  1996     1997  \\\n",
       "0  0.0  0.000000  0.000000  0.0  0.0  0.071942  0.000000   0.0   0.0  0.00000   \n",
       "1  0.0  0.000000  0.000000  0.0  0.0  0.000000  0.000000   0.0   0.0  0.00000   \n",
       "2  0.0  0.000000  0.000000  0.0  0.0  0.000000  0.000000   0.0   0.0  0.00000   \n",
       "3  0.0  0.047541  0.000000  0.0  0.0  0.000000  0.000000   0.0   0.0  0.00000   \n",
       "4  0.0  0.030700  0.038514  0.0  0.0  0.000000  0.041062   0.0   0.0  0.07191   \n",
       "\n",
       "   ...  year old     years  years ago  years later     yes  york     young  \\\n",
       "0  ...  0.058335  0.000000    0.00000          0.0  0.0000   0.0  0.000000   \n",
       "1  ...  0.000000  0.000000    0.00000          0.0  0.0535   0.0  0.078474   \n",
       "2  ...  0.000000  0.000000    0.00000          0.0  0.0000   0.0  0.000000   \n",
       "3  ...  0.000000  0.000000    0.00000          0.0  0.0000   0.0  0.000000   \n",
       "4  ...  0.000000  0.039311    0.07021          0.0  0.0000   0.0  0.042771   \n",
       "\n",
       "   young man   younger  zero  \n",
       "0   0.000000  0.000000   0.0  \n",
       "1   0.077244  0.000000   0.0  \n",
       "2   0.000000  0.000000   0.0  \n",
       "3   0.000000  0.057325   0.0  \n",
       "4   0.000000  0.000000   0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "UZ2Py6HJbgVs",
    "outputId": "0d3564ef-57fd-460a-a60e-5882da2a9944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>years later</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>young man</th>\n",
       "      <th>younger</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100   12   13   15   17  1995  1996  1997  ...  year old  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  ...       0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  ...       0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  ...       0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  ...       0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  ...       0.0   \n",
       "\n",
       "     years  years ago  years later  yes  york  young  young man  younger  zero  \n",
       "0  0.05356        0.0          0.0  0.0   0.0    0.0        0.0      0.0   0.0  \n",
       "1  0.00000        0.0          0.0  0.0   0.0    0.0        0.0      0.0   0.0  \n",
       "2  0.00000        0.0          0.0  0.0   0.0    0.0        0.0      0.0   0.0  \n",
       "3  0.00000        0.0          0.0  0.0   0.0    0.0        0.0      0.0   0.0  \n",
       "4  0.00000        0.0          0.0  0.0   0.0    0.0        0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), \n",
    "                                 columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQnaB7ZobuTL"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "MxzX6yfXb3-k",
    "outputId": "bfac4200-ea23-4c05-b2ff-2d30f96daad5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'acc_train': 0.93875, 'acc_test': 0.82, 'vect_type': 'tfidf'}\n",
      "{'model': 'MultinomialNB', 'acc_train': 0.883125, 'acc_test': 0.7725, 'vect_type': 'tfidf'}\n",
      "{'model': 'RandomForestClassifier', 'acc_train': 0.99375, 'acc_test': 0.69, 'vect_type': 'tfidf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.975625</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                   model vect_type\n",
       "0    0.8375   1.000000      LogisticRegression     Count\n",
       "1    0.7850   0.975625           MultinomialNB     Count\n",
       "2    0.7250   0.990000  RandomForestClassifier     Count\n",
       "3    0.8200   0.938750      LogisticRegression     tfidf\n",
       "4    0.7725   0.883125           MultinomialNB     tfidf\n",
       "5    0.6900   0.993750  RandomForestClassifier     tfidf"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in models:\n",
    "    result = assess_model(\n",
    "        model,\n",
    "        X_train_vectorized, X_test_vectorized, y_train, y_test,\n",
    "        vect_type='tfidf')\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7iTmvPBY04W"
   },
   "source": [
    "# Using NLTK to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LI4fS7ZUgA0c"
   },
   "source": [
    "### Importing the data fresh to avoid variable collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "t_QH7TqlgNQ5",
    "outputId": "a32764ca-05fb-476e-d70a-99abb65aecdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Total reviews: 2000\n",
      "Positive reviews: 1000\n",
      "Negative reviews: 1000\n"
     ]
    }
   ],
   "source": [
    "df = load_movie_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EX1GfzLxKZhe"
   },
   "source": [
    "### Cleaning function to apply to each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "XX-1OOavJpug",
    "outputId": "039cc6f8-e7b4-49c0-d75d-d2c482f6bd33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[movies, based, video, games, street, fighter, mario, bros, never, generated, much, interest, box, office, first, mortal, kombat, movie, came, surprisingly, well, simple, story, pulsating, soundtr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, actor, james, woods, said, paraphrasing, sex, messy, right, truly, profound, statement, one, could, made, entire, mad, slasher, genre, replace, sex, mad, slasher, film, uninformed, souls, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[like, good, action, film, metro, action, keeps, involved, action, films, action, sequences, conventional, attention, detracted, diverted, thoughts, ghost, darkness, opened, months, ago, film, act...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[first, troy, beyer, wrote, critically, panned, makes, directorial, debut, writing, directing, starring, sub, par, film, women, talking, sex, though, without, redeeming, qualities, film, bad, basi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thought, baz, luhrmann, radical, take, williamshakespeare, sromeo, juliet, wild, wait, see, tony, award, winning, stage, director, julie, taymor, thelionking, thebroadwaymusical, bard, titusandro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  [movies, based, video, games, street, fighter, mario, bros, never, generated, much, interest, box, office, first, mortal, kombat, movie, came, surprisingly, well, simple, story, pulsating, soundtr...   \n",
       "1  [great, actor, james, woods, said, paraphrasing, sex, messy, right, truly, profound, statement, one, could, made, entire, mad, slasher, genre, replace, sex, mad, slasher, film, uninformed, souls, ...   \n",
       "2  [like, good, action, film, metro, action, keeps, involved, action, films, action, sequences, conventional, attention, detracted, diverted, thoughts, ghost, darkness, opened, months, ago, film, act...   \n",
       "3  [first, troy, beyer, wrote, critically, panned, makes, directorial, debut, writing, directing, starring, sub, par, film, women, talking, sex, though, without, redeeming, qualities, film, bad, basi...   \n",
       "4  [thought, baz, luhrmann, radical, take, williamshakespeare, sromeo, juliet, wild, wait, see, tony, award, winning, stage, director, julie, taymor, thelionking, thebroadwaymusical, bard, titusandro...   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "df_nltk = pd.DataFrame()\n",
    "df_nltk['text'] = df.text.apply(clean_doc)\n",
    "df_nltk['sentiment'] = df.sentiment\n",
    "df_nltk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYQ1cyZgg7d8"
   },
   "source": [
    "### Reformat reviews for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "7Or1gRcRhOID",
    "outputId": "8435a535-f26e-4d18-b515-a8f674a2159d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movies based video games street fighter mario bros never generated much interest box office first mortal kombat movie came surprisingly well simple story pulsating soundtrack lots awesomely choreo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great actor james woods said paraphrasing sex messy right truly profound statement one could made entire mad slasher genre replace sex mad slasher film uninformed souls mad slasher genre sub genre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like good action film metro action keeps involved action films action sequences conventional attention detracted diverted thoughts ghost darkness opened months ago film action bland uninvolving in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first troy beyer wrote critically panned makes directorial debut writing directing starring sub par film women talking sex though without redeeming qualities film bad basic story follows three sin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thought baz luhrmann radical take williamshakespeare sromeo juliet wild wait see tony award winning stage director julie taymor thelionking thebroadwaymusical bard titusandronicus audacious bloody...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  movies based video games street fighter mario bros never generated much interest box office first mortal kombat movie came surprisingly well simple story pulsating soundtrack lots awesomely choreo...   \n",
       "1  great actor james woods said paraphrasing sex messy right truly profound statement one could made entire mad slasher genre replace sex mad slasher film uninformed souls mad slasher genre sub genre...   \n",
       "2  like good action film metro action keeps involved action films action sequences conventional attention detracted diverted thoughts ghost darkness opened months ago film action bland uninvolving in...   \n",
       "3  first troy beyer wrote critically panned makes directorial debut writing directing starring sub par film women talking sex though without redeeming qualities film bad basic story follows three sin...   \n",
       "4  thought baz luhrmann radical take williamshakespeare sromeo juliet wild wait see tony award winning stage director julie taymor thelionking thebroadwaymusical bard titusandronicus audacious bloody...   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "for review in df_nltk.text:\n",
    "    review = \" \".join(review)\n",
    "    documents.append(review)\n",
    "  \n",
    "sentiment = list(df_nltk.sentiment)\n",
    "new_df = pd.DataFrame({'text': documents, 'sentiment': sentiment})\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq-ev_ggh9DU"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pfizhRrdGXr"
   },
   "outputs": [],
   "source": [
    "X = new_df.text\n",
    "y = new_df.sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAB97oF2LPSy"
   },
   "source": [
    "### Vectorize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aQvOH2JnJNRL",
    "outputId": "7893339c-dc24-4122-f5d7-748e109cf8b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=None, ngram_range=(1,1), \n",
    "                             stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "IUZR3p7KbHrZ",
    "outputId": "b05d46cb-cba4-4185-846a-9d3598277e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 35240)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaaahhhh</th>\n",
       "      <th>aaaahhhs</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aalyah</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aardman</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaaaaaahhhh  aaaahhhs  aahs  aaliyah  aalyah  aamir  aardman  \\\n",
       "0  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "1  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "2  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "3  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "4  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "\n",
       "   aaron  ...  zukovsky  zulu  zundel  zurg  zus  zweibel  zwick  zwigoff  \\\n",
       "0    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "1    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "2    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "3    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "4    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "\n",
       "   zycie  zzzzzzz  \n",
       "0    0.0      0.0  \n",
       "1    0.0      0.0  \n",
       "2    0.0      0.0  \n",
       "3    0.0      0.0  \n",
       "4    0.0      0.0  \n",
       "\n",
       "[5 rows x 35240 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), \n",
    "                                  columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "GtGOFiU5jIVK",
    "outputId": "28274147-b58b-4dcd-deaa-be0902426e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 35240)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaaahhhh</th>\n",
       "      <th>aaaahhhs</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aalyah</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aardman</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaaaaaahhhh  aaaahhhs  aahs  aaliyah  aalyah  aamir  aardman  \\\n",
       "0  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "1  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "2  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "3  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "4  0.0  0.0           0.0       0.0   0.0      0.0     0.0    0.0      0.0   \n",
       "\n",
       "   aaron  ...  zukovsky  zulu  zundel  zurg  zus  zweibel  zwick  zwigoff  \\\n",
       "0    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "1    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "2    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "3    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "4    0.0  ...       0.0   0.0     0.0   0.0  0.0      0.0    0.0      0.0   \n",
       "\n",
       "   zycie  zzzzzzz  \n",
       "0    0.0      0.0  \n",
       "1    0.0      0.0  \n",
       "2    0.0      0.0  \n",
       "3    0.0      0.0  \n",
       "4    0.0      0.0  \n",
       "\n",
       "[5 rows x 35240 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(X_test_vectorized.shape)\n",
    "X_test_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzW-8HmQjSxb"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=42, solver='lbfgs'),\n",
    "          MultinomialNB(),\n",
    "          RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5NLlkIg_YDUA",
    "outputId": "7c7543d3-3463-4960-b57d-999e2c054ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'acc_train': 0.985, 'acc_test': 0.8125, 'vect_type': 'Tfidf'}\n",
      "{'model': 'MultinomialNB', 'acc_train': 0.975625, 'acc_test': 0.8025, 'vect_type': 'Tfidf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\City_Year\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'RandomForestClassifier', 'acc_train': 0.99, 'acc_test': 0.705, 'vect_type': 'Tfidf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.975625</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                   model vect_type\n",
       "0    0.8125   0.985000      LogisticRegression     Tfidf\n",
       "1    0.8025   0.975625           MultinomialNB     Tfidf\n",
       "2    0.7050   0.990000  RandomForestClassifier     Tfidf"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in models:\n",
    "    result = assess_model(\n",
    "        model,\n",
    "        X_train_vectorized, X_test_vectorized, y_train, y_test,\n",
    "        vect_type='Tfidf')\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "A-6kHJfSjvk0",
    "outputId": "95aea272-4e94-48d0-fc3e-b2a61f62f57f"
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(\n",
    "        #hyper params\n",
    "        n_jobs = -1,\n",
    ")\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train, eval_metric = 'auc')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_423_Document_Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
