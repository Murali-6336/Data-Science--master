{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "- [5 Reasons ‚ÄúLogistic Regression‚Äù should be the first thing you learn when becoming a Data Scientist](https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4)\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - more code and math, with gradient descent and the logistic loss function\n",
    "- more classification models from scikit-learn: [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math varies significantly, but the API and interpretation are fairly similar\n",
    "- More on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), how audio features were actually calculated in the FMA dataset used at the end of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options for regression. Recall that **linear regression** is helpful when predicting a real number along some continuum without a restricted range. Things like income and age.\n",
    "\n",
    "But what about . . .\n",
    "* probabilities\n",
    "* binary values (sick vs. healthy, male vs. female)\n",
    "* approval rating (0% to 100%)\n",
    "\n",
    "We need some \"squishification\" process to map numbers from a real number continuum to the unit interval (X range $-\\infty$ to $\\infty$, Y range 0 to 1). We need a **cumulative density function** - most commonly the **[sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function)**. This function in particular is useful because its calculous properties give it nice behaviors. (e^x derivative is e^x) Another common CDF is the **[probit function](https://en.wikipedia.org/wiki/Probit)** for probabilities.\n",
    "\n",
    "With logistic regression, we can even model general multinomial classification problems by combining several logistic regressions to predict membership in various classes and outputting the class that is most likely.\n",
    "\n",
    "At its heart, logistic regression is still linear. That is, the underlying math and optimization follow traditional linear regression. However, our coefficients won't have intuitive linear interpretation.\n",
    "\n",
    "$S(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + 1}$\n",
    "\n",
    "\n",
    "**What data science methods are used at work?** (source: [Kaggle 2017 Survey](https://www.kaggle.com/surveys/2017))\n",
    "![](img/kaggle-common-algos.PNG)\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Linear vs. Logistic, Return of the Titanic üö¢\n",
    "\n",
    "To pull Titanic data from Kaggle:\n",
    "* create account\n",
    "* generate API Key and `kaggle.json`\n",
    "* join [Titanic competition](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "The [Kaggle API](https://github.com/Kaggle/kaggle-api) enables lots of convenient methods for interacting with Kaggle.\n",
    "\n",
    "Here's how the data were sourced:\n",
    "```python\n",
    "!pip install kaggle\n",
    "\n",
    "import os, json\n",
    "\n",
    "path_to_config = \"../kaggle.json\"\n",
    "kaggle_config = json.loads(open(path_to_config).read())\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_config['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_config['key']\n",
    "\n",
    "!kaggle competitions download -c titanic -p datasets/titanic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "-PtztP8YlFym",
    "outputId": "8b18c64d-988a-44b1-e988-9de3fa61a5d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How would we try to do this with linear regression?\n",
    "train_df = pd.read_csv('datasets/titanic/train.csv').dropna()\n",
    "test_df = pd.read_csv('datasets/titanic/train.csv').dropna()  # Unlabeled, for Kaggle submission\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QiZn2p1K8DED",
    "outputId": "be8b1a4c-ca08-4bba-98ed-3cda0942499c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.08389810726550939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.66567686, 0.68168731, 0.52351404, 0.74909452, 0.4779952 ,\n",
       "       0.58445856, 0.73115482, 0.91675714, 0.57710857, 0.43722395])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['Pclass', 'Age', 'Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "X = train_df[predictors]\n",
    "y = train_df[target]\n",
    "\n",
    "linear_reg = LinearRegression().fit(X, y)\n",
    "print('score:', linear_reg.score(X, y))\n",
    "\n",
    "linear_reg.predict(test_df[predictors])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you \"partially\" survive? You either survived or did not, like how our target column is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fcxfpsjdFJwM",
    "outputId": "590a3bba-67fe-48b4-bf6e-91e67bd29bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': -0.008293140798696792,\n",
       " 'Fare': 0.00048775407963190954,\n",
       " 'Pclass': -0.08596294986392504}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{attr: coef for attr, coef in zip(predictors, linear_reg.coef_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AFiisZU7_2Fr",
    "outputId": "97e9d9e2-6c2f-49b9-9955-e956b8d42e2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14845883])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = np.array([[1, 5, 500]])  # Rich 5-year old in first class\n",
    "linear_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can survial be greater than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "dpUm8Dl-u2aB",
    "outputId": "44bc9b92-52ac-4e13-ab03-e87cbfd5fea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103825136612022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print(log_reg.score(X, y))\n",
    "\n",
    "log_reg.predict(test_df[predictors])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r7xWwqBrFuWL",
    "outputId": "4ea8705c-82b5-4378-cd8d-d0aca8e5d19e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "flF3pcMHGGWw",
    "outputId": "4d5eef4c-e431-4486-b70f-dde06b7e3862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02485552, 0.97514448])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict_proba(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Bq-54noR1uE",
    "outputId": "b2650236-5573-4f84-d1a8-ce8bc6d1de17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': -0.02912512677284113,\n",
       " 'Fare': 0.004803700867242946,\n",
       " 'Pclass': -0.04550170440859573}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the math?\n",
    "{attr: coef for attr, coef in zip(predictors, log_reg.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tj0mNL7_XWNV",
    "outputId": "effe14e5-839d-4ee0-e38d-fb80eef80ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45878264])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AroeYscqR75f"
   },
   "outputs": [],
   "source": [
    "# The logistic sigmoid \"squishing\" function, implemented to accept numpy arrays\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "804BA7s0SggQ",
    "outputId": "61e0fcc7-adf9-4077-ba27-de875165cea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97514448]])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, clearly a more appropriate model in this situation! For more on the math, [see this Wikipedia example](https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study).\n",
    "\n",
    "**Note:** while the sign (-/+) of coefficients provides information on the relationship between X and Y, we can't infer that a one-unit difference in X corresponds to a one-unit difference in Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multinomial Logistic Regression\n",
    "\n",
    "[Absenteeism at work dataset](http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) has 21 classes. `sklearn.linear_model.LogisticRegression` automatically handles more than two classes by essentially treating each label as different (1) from some base class (0).\n",
    "\n",
    "Here's how the data were sourced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = ('http://archive.ics.uci.edu/ml/'\n",
    "            'machine-learning-databases/00445/'\n",
    "            'Absenteeism_at_work_AAA.zip')\n",
    "\n",
    "extract_zip_url(data_url, 'datasets/abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0  11                  26                 7                3        1   \n",
       "1  36                   0                 7                3        1   \n",
       "2   3                  23                 7                4        1   \n",
       "3   7                   7                 7                5        1   \n",
       "4  11                  23                 7                5        1   \n",
       "\n",
       "   Transportation expense  Distance from Residence to Work  Service time  Age  \\\n",
       "0                     289                               36            13   33   \n",
       "1                     118                               13            18   50   \n",
       "2                     179                               51            18   38   \n",
       "3                     279                                5            14   39   \n",
       "4                     289                               36            13   33   \n",
       "\n",
       "   Work load Average/day   Hit target  Disciplinary failure  Education  Son  \\\n",
       "0                 239.554          97                     0          1    2   \n",
       "1                 239.554          97                     1          1    1   \n",
       "2                 239.554          97                     0          1    0   \n",
       "3                 239.554          97                     0          1    2   \n",
       "4                 239.554          97                     0          1    2   \n",
       "\n",
       "   Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \\\n",
       "0               1              0    1      90     172               30   \n",
       "1               1              0    0      98     178               31   \n",
       "2               1              0    0      89     170               31   \n",
       "3               1              1    0      68     168               24   \n",
       "4               1              0    1      90     172               30   \n",
       "\n",
       "   Absenteeism time in hours  \n",
       "0                          4  \n",
       "1                          0  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          2  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/abs/Absenteeism_at_work.csv', sep=';')\n",
    "pd.options.display.max_columns = df.shape[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinom_logistic(df, target, predictors, test_size=0.5, random_state=42):\n",
    "    X = df[predictors]\n",
    "    y = df[target]\n",
    "\n",
    "    if test_size:\n",
    "        X_train, X_test, Y_train, Y_test = (\n",
    "            train_test_split(X, y, test_size=test_size, \n",
    "                             random_state=random_state)\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test = [X] * 2\n",
    "        Y_train, Y_test = [y] * 2\n",
    "        \n",
    "    model = LogisticRegression(random_state=random_state, solver='lbfgs', \n",
    "                               multi_class='multinomial', max_iter=5000)\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('score:', model.score(X_test, Y_test))\n",
    "    \n",
    "    return model, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5121621621621621\n"
     ]
    }
   ],
   "source": [
    "target = 'Reason for absence'\n",
    "predictors = sorted(list(set(df.columns) - \n",
    "                         set(['ID', 'Reason for absence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5121621621621621\n"
     ]
    }
   ],
   "source": [
    "# without train-test\n",
    "model = multinom_logistic(df, target, predictors, test_size=None, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.3810810810810811\n"
     ]
    }
   ],
   "source": [
    "model = multinom_logistic(df, target, predictors, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.3783783783783784\n"
     ]
    }
   ],
   "source": [
    "# smaller test size makes worse score\n",
    "model = multinom_logistic(df, target, predictors, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Example 3: real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "SsySnuKaKtQf",
    "outputId": "d2855f29-b12c-4c1d-b86e-5867510e797a"
   },
   "outputs": [],
   "source": [
    "# # downloads 1.36 GB\n",
    "# data_url = 'https://os.unil.cloud.switch.ch/fma/fma_metadata.zip'\n",
    "# extract_zip_url(data_url, 'datasets/fma', flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = pd.read_csv('datasets/fma/tracks.csv', nrows=3, \n",
    "                      header=None)\n",
    "cols = (headers.T.fillna('')\n",
    "               .apply(lambda x: ('_'.join(x.astype(str))\n",
    "                                    .strip('_')), axis=1))\n",
    "\n",
    "tracks = pd.read_csv('datasets/fma/tracks.csv', skiprows=3, \n",
    "                     header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_qzn-IjIM1Pw",
    "outputId": "8b4fd4af-feff-49f0-d2ec-da238c58b716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20980, 53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>album_comments</th>\n",
       "      <th>album_date_created</th>\n",
       "      <th>album_date_released</th>\n",
       "      <th>album_engineer</th>\n",
       "      <th>album_favorites</th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_information</th>\n",
       "      <th>album_listens</th>\n",
       "      <th>album_producer</th>\n",
       "      <th>album_tags</th>\n",
       "      <th>album_title</th>\n",
       "      <th>album_tracks</th>\n",
       "      <th>album_type</th>\n",
       "      <th>artist_active_year_begin</th>\n",
       "      <th>artist_active_year_end</th>\n",
       "      <th>artist_associated_labels</th>\n",
       "      <th>artist_bio</th>\n",
       "      <th>artist_comments</th>\n",
       "      <th>artist_date_created</th>\n",
       "      <th>artist_favorites</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_members</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_related_projects</th>\n",
       "      <th>artist_tags</th>\n",
       "      <th>artist_website</th>\n",
       "      <th>artist_wikipedia_page</th>\n",
       "      <th>set_split</th>\n",
       "      <th>set_subset</th>\n",
       "      <th>track_bit_rate</th>\n",
       "      <th>track_comments</th>\n",
       "      <th>track_composer</th>\n",
       "      <th>track_date_created</th>\n",
       "      <th>track_date_recorded</th>\n",
       "      <th>track_duration</th>\n",
       "      <th>track_favorites</th>\n",
       "      <th>track_genre_top</th>\n",
       "      <th>track_genres</th>\n",
       "      <th>track_genres_all</th>\n",
       "      <th>track_information</th>\n",
       "      <th>track_interest</th>\n",
       "      <th>track_language_code</th>\n",
       "      <th>track_license</th>\n",
       "      <th>track_listens</th>\n",
       "      <th>track_lyricist</th>\n",
       "      <th>track_number</th>\n",
       "      <th>track_publisher</th>\n",
       "      <th>track_tags</th>\n",
       "      <th>track_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:19</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>207</td>\n",
       "      <td>3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1126</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Street Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-11-26 01:49:35</td>\n",
       "      <td>2006-12-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>&lt;p&gt;Here's the proof in the pudding that the as...</td>\n",
       "      <td>1681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['lafms']</td>\n",
       "      <td>Live at LACE</td>\n",
       "      <td>2</td>\n",
       "      <td>Live Performance</td>\n",
       "      <td>1978-01-01 00:00:00</td>\n",
       "      <td>1998-01-01 00:00:00</td>\n",
       "      <td>Los Angeles Free Music Society, Harbinger Sound</td>\n",
       "      <td>&lt;p&gt;Airway was a musical ensemble based within ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:47:22</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>34.052234</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>-118.243685</td>\n",
       "      <td>Rick Potts, Juan Gomez, Tom Recchion, Joe Pott...</td>\n",
       "      <td>Airway</td>\n",
       "      <td>Los Angeles Free Music Society, the Banshees, ...</td>\n",
       "      <td>['airway']</td>\n",
       "      <td>http://www.lafms.com/</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Airway_(band)</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:42</td>\n",
       "      <td>1978-04-27 00:00:00</td>\n",
       "      <td>1233</td>\n",
       "      <td>2</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>[1, 32]</td>\n",
       "      <td>[32, 1, 38]</td>\n",
       "      <td>&lt;p&gt;Recorded live in downtown Los Angeles at th...</td>\n",
       "      <td>2559</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['lafms']</td>\n",
       "      <td>Side A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    track_id  album_comments   album_date_created  album_date_released  \\\n",
       "0          2               0  2008-11-26 01:44:45  2009-01-05 00:00:00   \n",
       "1          3               0  2008-11-26 01:44:45  2009-01-05 00:00:00   \n",
       "2          5               0  2008-11-26 01:44:45  2009-01-05 00:00:00   \n",
       "9        134               0  2008-11-26 01:44:45  2009-01-05 00:00:00   \n",
       "12       137               1  2008-11-26 01:49:35  2006-12-01 00:00:00   \n",
       "\n",
       "   album_engineer  album_favorites  album_id  \\\n",
       "0             NaN                4         1   \n",
       "1             NaN                4         1   \n",
       "2             NaN                4         1   \n",
       "9             NaN                4         1   \n",
       "12            NaN                2        59   \n",
       "\n",
       "                                    album_information  album_listens  \\\n",
       "0                                             <p></p>           6073   \n",
       "1                                             <p></p>           6073   \n",
       "2                                             <p></p>           6073   \n",
       "9                                             <p></p>           6073   \n",
       "12  <p>Here's the proof in the pudding that the as...           1681   \n",
       "\n",
       "   album_producer album_tags           album_title  album_tracks  \\\n",
       "0             NaN         []  AWOL - A Way Of Life             7   \n",
       "1             NaN         []  AWOL - A Way Of Life             7   \n",
       "2             NaN         []  AWOL - A Way Of Life             7   \n",
       "9             NaN         []  AWOL - A Way Of Life             7   \n",
       "12            NaN  ['lafms']          Live at LACE             2   \n",
       "\n",
       "          album_type artist_active_year_begin artist_active_year_end  \\\n",
       "0              Album      2006-01-01 00:00:00                    NaN   \n",
       "1              Album      2006-01-01 00:00:00                    NaN   \n",
       "2              Album      2006-01-01 00:00:00                    NaN   \n",
       "9              Album      2006-01-01 00:00:00                    NaN   \n",
       "12  Live Performance      1978-01-01 00:00:00    1998-01-01 00:00:00   \n",
       "\n",
       "                           artist_associated_labels  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "9                                               NaN   \n",
       "12  Los Angeles Free Music Society, Harbinger Sound   \n",
       "\n",
       "                                           artist_bio  artist_comments  \\\n",
       "0   <p>A Way Of Life, A Collective of Hip-Hop from...                0   \n",
       "1   <p>A Way Of Life, A Collective of Hip-Hop from...                0   \n",
       "2   <p>A Way Of Life, A Collective of Hip-Hop from...                0   \n",
       "9   <p>A Way Of Life, A Collective of Hip-Hop from...                0   \n",
       "12  <p>Airway was a musical ensemble based within ...                0   \n",
       "\n",
       "    artist_date_created  artist_favorites  artist_id  artist_latitude  \\\n",
       "0   2008-11-26 01:42:32                 9          1        40.058324   \n",
       "1   2008-11-26 01:42:32                 9          1        40.058324   \n",
       "2   2008-11-26 01:42:32                 9          1        40.058324   \n",
       "9   2008-11-26 01:42:32                 9          1        40.058324   \n",
       "12  2008-11-26 01:47:22                 5         53        34.052234   \n",
       "\n",
       "    artist_location  artist_longitude  \\\n",
       "0        New Jersey        -74.405661   \n",
       "1        New Jersey        -74.405661   \n",
       "2        New Jersey        -74.405661   \n",
       "9        New Jersey        -74.405661   \n",
       "12  Los Angeles, CA       -118.243685   \n",
       "\n",
       "                                       artist_members artist_name  \\\n",
       "0   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "1   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "2   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "9   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "12  Rick Potts, Juan Gomez, Tom Recchion, Joe Pott...      Airway   \n",
       "\n",
       "                              artist_related_projects artist_tags  \\\n",
       "0   The list of past projects is 2 long but every1...    ['awol']   \n",
       "1   The list of past projects is 2 long but every1...    ['awol']   \n",
       "2   The list of past projects is 2 long but every1...    ['awol']   \n",
       "9   The list of past projects is 2 long but every1...    ['awol']   \n",
       "12  Los Angeles Free Music Society, the Banshees, ...  ['airway']   \n",
       "\n",
       "                             artist_website  \\\n",
       "0   http://www.AzillionRecords.blogspot.com   \n",
       "1   http://www.AzillionRecords.blogspot.com   \n",
       "2   http://www.AzillionRecords.blogspot.com   \n",
       "9   http://www.AzillionRecords.blogspot.com   \n",
       "12                    http://www.lafms.com/   \n",
       "\n",
       "                         artist_wikipedia_page set_split set_subset  \\\n",
       "0                                          NaN  training      small   \n",
       "1                                          NaN  training     medium   \n",
       "2                                          NaN  training      small   \n",
       "9                                          NaN  training     medium   \n",
       "12  http://en.wikipedia.org/wiki/Airway_(band)  training      large   \n",
       "\n",
       "    track_bit_rate  track_comments track_composer   track_date_created  \\\n",
       "0           256000               0            NaN  2008-11-26 01:48:12   \n",
       "1           256000               0            NaN  2008-11-26 01:48:14   \n",
       "2           256000               0            NaN  2008-11-26 01:48:20   \n",
       "9           256000               0            NaN  2008-11-26 01:43:19   \n",
       "12          256000               0            NaN  2008-11-26 01:43:42   \n",
       "\n",
       "    track_date_recorded  track_duration  track_favorites track_genre_top  \\\n",
       "0   2008-11-26 00:00:00             168                2         Hip-Hop   \n",
       "1   2008-11-26 00:00:00             237                1         Hip-Hop   \n",
       "2   2008-11-26 00:00:00             206                6         Hip-Hop   \n",
       "9   2008-11-26 00:00:00             207                3         Hip-Hop   \n",
       "12  1978-04-27 00:00:00            1233                2    Experimental   \n",
       "\n",
       "   track_genres track_genres_all  \\\n",
       "0          [21]             [21]   \n",
       "1          [21]             [21]   \n",
       "2          [21]             [21]   \n",
       "9          [21]             [21]   \n",
       "12      [1, 32]      [32, 1, 38]   \n",
       "\n",
       "                                    track_information  track_interest  \\\n",
       "0                                                 NaN            4656   \n",
       "1                                                 NaN            1470   \n",
       "2                                                 NaN            1933   \n",
       "9                                                 NaN            1126   \n",
       "12  <p>Recorded live in downtown Los Angeles at th...            2559   \n",
       "\n",
       "   track_language_code                                      track_license  \\\n",
       "0                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "1                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "2                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "9                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "12                  en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "\n",
       "    track_listens track_lyricist  track_number track_publisher track_tags  \\\n",
       "0            1293            NaN             3             NaN         []   \n",
       "1             514            NaN             4             NaN         []   \n",
       "2            1151            NaN             6             NaN         []   \n",
       "9             943            NaN             5             NaN         []   \n",
       "12           1278            NaN             1             NaN  ['lafms']   \n",
       "\n",
       "     track_title  \n",
       "0           Food  \n",
       "1   Electric Ave  \n",
       "2     This World  \n",
       "9   Street Music  \n",
       "12        Side A  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tracks.shape)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'track_genre_top'\n",
    "target_aliases = ['track_genres', 'track_genres_all']\n",
    "predictors = ['track_duration', 'track_favorites', 'track_interest', \n",
    "              'track_listens', 'artist_latitude', 'artist_longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.dropna(subset=[target]+predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.40896091515729266\n"
     ]
    }
   ],
   "source": [
    "model, X_test, Y_test = (\n",
    "    multinom_logistic(tracks, target, predictors,\n",
    "                      test_size=0.5, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "d = {key:0 for key in set(Y_test)}\n",
    "for actual, predict in zip(Y_test, predictions):\n",
    "    if actual==predict:\n",
    "        d[actual] += 1\n",
    "\n",
    "counts = Counter(Y_test)\n",
    "\n",
    "for key, value in d.items():\n",
    "    d[key] = d[key] / counts[key]\n",
    "\n",
    "prev = pd.Series(counts, name='% prevalence') / len(Y_test) * 100\n",
    "correct = pd.Series(d, name='% correct') * 100\n",
    "\n",
    "print(pd.DataFrame([prev, correct]).T.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": [
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
